\documentclass[10pt,a4paper]{article}
\usepackage{times}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{durhampaper}
\usepackage{subfigure}
% \usepackage{harvard}
% \usepackage[moderate]{savetrees}
\usepackage{url}

\title{Facial Liveness Testing: For The Web}
\author{} % leave; your name goes into \student{}
\student{Ryan Collins}
\supervisor{Prof A. Krokhin}
\degree{MEng Computer Science}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
% These instructions give you guidelines for preparing the final paper.  DO NOT change any settings, such as margins and font sizes.  Just use this as a template and modify the contents into your final paper.  Do not cite references in the abstract.

% The abstract must be a Structured Abstract with the headings {\bf Context/Background}, {\bf Aims}, {\bf Method}, {\bf Results}, and {\bf Conclusions}.  This section should not be longer than half of a page, and having no more than one or two sentences under each heading is advised.
\paragraph{Context/Background}
    TODO

\paragraph{Aims}
    TODO

\paragraph{Method}
    TODO

\paragraph{Results}
    TODO
\paragraph{Conclusions}
    TODO

\end{abstract}

\begin{keywords}
Facial liveness, convolutional neural networks, image quality metrics
\end{keywords}

\section{Introduction}
    % What is the project about?
    Currently, username and password authentication is commonplace throughout the web. However, username and password
    based authentication systems have a number of problems. Some common passwords can be broken using dictionary attacks,
    especially if they consist partially or entirely of a word in a standard dictionary. Furthermore, the process of shoulder surfing is possible (watching out
    for someone's password, and how they type it).

    An easy to use system is necessary to remove the choice from the user (in terms of password), relying on the user being automatically
    detected, and several confirmation methods to ensure the user is indeed who they say they are (and not just someone spoofing the system).
    Before such a system is developed, a facial liveness testing method must be found that operated in near real-time, and that is fairly accurate.


\section{Related Work}
    - First basic metrics
    - image Quality assessment (different types of image quality metrics used ,and why they should be effective). Drawbacks of these
    - movement based assessment (requiring actions to be performed, and their problems).
    - Deep Learning methods (what methods exist, their performance)
    - 3D mask prevention methods (kinect based ones that require 3D input, or SFM, which isn't really valid here)
\section{Solution}
    % Solution to the problem
    \subsection{Image Quality Assessment based liveness test}
        For 2D spoofing attacks, spoofed images are typically lower quality than the real images, and thus by measuring the image quality
        one can train a classifier to detect real and spoofed images respectively.

        The method used, based on \textbf{CITE the paper we use here}, implements 24 different metrics (with varying differences), and produces
        a vector for each image. Initially, classification was done using a Support Vector Machine (SVM), but after experimentation this proved to be fairly
        unreliable (yielding 70\% accuracy on the test set). The classifier was later changed to use Linear Discriminant Analysis (LDA) which yielded a much improved
        accuracy (96\% accuracy on the test set). \textbf{TODO: give more accuracy figures of accuracy here, I can't remember the exact numbers}.

    \subsection{A system for preventing 3D spoofing attacks}
        While the systems before might go partially towards preventing 3D spoofing attacks, though primarily considering the 2D image, we now propose a method
        that is designed for classifying facial liveness based on a 3D point cloud.

        \subsubsection{Point Cloud Reconstruction}
            In order to classify an image/video, a 3D point cloud needs to be created, containing many 3D points $(x,y,z)$
            of a user's face. While 3d reconstruction is easier with videos (using structure from motion or other multiview based methods),
            there also exist image-based reconstruction methods such as vrn \textbf{CITE VRN network model here for 3d reconstruction}, which are
            more specific and designed for reconstructing faces based on images.

        \subsubsection{3D point cloud classification}
            Once the 3D reconstruction is obtained, one can then classify this using some model to produce the fake/real metric.

            For points, PointNet is a model that can be used \textbf{EXPLAIN POINTNET}

            However, as we are using voxels, there is a more specialised architecutre called Voxnet that is designed for classifying
            3d volume-based objects. This is the model used here.
\section{Results}
    % based on the solution, what results did we yield? What did we find out?
    TODO results
\section{Evaluation}
    % How well our system works, how well did it assess stuff, and how it can be improved.
    % what are the uses of our research? e.g. influence and improve the design of xyz...
    TODO evaluation


    % Improvements:
    % 3D attacks more difficult. One could extend this method using 3D reconstruction (sfm based on videos)
    % then recovering 3D details, and using these as input features.
    % this would allow for 3D reconstruction to some extent. Would require video input.
\section{Conclusions}
    % overall, what did the project show?


\bibliographystyle{dinat}
\bibliography{report}

\end{document}