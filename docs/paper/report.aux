\relax 
\@writefile{toc}{\contentsline {paragraph}{Context}{1}}
\@writefile{toc}{\contentsline {paragraph}{Aims}{1}}
\@writefile{toc}{\contentsline {paragraph}{Method}{1}}
\@writefile{toc}{\contentsline {paragraph}{Results}{1}}
\@writefile{toc}{\contentsline {paragraph}{Conclusions}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\citation{FaceSpoofingAttacksStudy}
\citation{FaceSpoofingAttacksStudy}
\citation{SFMClassifier}
\citation{ImageQualityAssessmentTest}
\citation{Patel2016CrossDatabaseFA}
\citation{AlexNet}
\citation{DeepNeuralNetworkDeployability}
\citation{DeepNeuralNetworkDeployability}
\citation{GoogLeNet}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}2D Spoofing Attacks}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1}General 2D image classification models}{2}}
\@writefile{toc}{\contentsline {paragraph}{AlexNet}{2}}
\@writefile{toc}{\contentsline {paragraph}{VGG16 Network}{2}}
\citation{GoogLeNet}
\citation{DeepNeuralNetworkDeployability}
\citation{DeepNeuralNetworkDeployability}
\citation{DeepNeuralNetworkDeployability}
\citation{DeepNeuralNetworkDeployability}
\citation{NUAADataset}
\citation{ReplayAttackDataset}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The Inception module with dimensionality reduction. Diagram taken from \cite  {GoogLeNet}.}}{3}}
\newlabel{InceptionArchitecture}{{1}{3}}
\@writefile{toc}{\contentsline {paragraph}{GoogLeNet Inception}{3}}
\@writefile{toc}{\contentsline {paragraph}{Residual Networks}{3}}
\@writefile{tdo}{\contentsline {todo}{Explain Resnets better}{3}}
\pgfsyspdfmark {pgfid1}{22445104}{25810249}
\pgfsyspdfmark {pgfid4}{36188921}{25807956}
\pgfsyspdfmark {pgfid5}{38040312}{25589066}
\@writefile{tdo}{\contentsline {todo}{Cite Residual Networks}{3}}
\pgfsyspdfmark {pgfid6}{6345015}{24237385}
\pgfsyspdfmark {pgfid9}{36188921}{22948308}
\pgfsyspdfmark {pgfid10}{38040312}{22729418}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2}Datasets}{3}}
\newlabel{Top1AccuracyOverNetwork}{{A.1}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Top 1 accuracy vs network. Chart and results from \cite  {DeepNeuralNetworkDeployability}}}{4}}
\newlabel{Top1AccuracyOverOperations}{{A.1}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Top 1 accuracy vs operations, where network size is proportional to parameters. Operations figures are for a single pass (e.g. predicting given a specific input). Chart and results from \cite  {DeepNeuralNetworkDeployability}}}{4}}
\citation{FaceSpoofingAttacksStudy}
\citation{3DMadDataset}
\citation{ImageQualityAssessmentTest}
\citation{VideoQualityOriginal}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.3}Temporal-based Liveness Tests}{5}}
\@writefile{tdo}{\contentsline {todo}{Add Eye tracking source}{5}}
\pgfsyspdfmark {pgfid11}{7328055}{46666940}
\@writefile{tdo}{\contentsline {todo}{Add face movement source}{5}}
\pgfsyspdfmark {pgfid16}{7328055}{46666940}
\pgfsyspdfmark {pgfid14}{36188921}{46664647}
\pgfsyspdfmark {pgfid15}{38040312}{46445757}
\pgfsyspdfmark {pgfid19}{36188921}{43804999}
\pgfsyspdfmark {pgfid20}{38040312}{43586109}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}3D Spoofing Attacks}{5}}
\@writefile{tdo}{\contentsline {todo}{Improve this section, explaining 3D based measures, more about the MAD dataset and attacks, etc.}{5}}
\pgfsyspdfmark {pgfid21}{7328055}{37885116}
\pgfsyspdfmark {pgfid24}{36188921}{37882823}
\pgfsyspdfmark {pgfid25}{38040312}{37663933}
\@writefile{toc}{\contentsline {section}{\numberline {III}Solution}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Image Quality Assessment based liveness test}{5}}
\@writefile{tdo}{\contentsline {todo}{TODO: give more accuracy figures of accuracy here, I can't remember the exact numbers}{5}}
\pgfsyspdfmark {pgfid26}{19964440}{27144926}
\@writefile{tdo}{\contentsline {todo}{Add more information here about each metric, the PyVideoQuality manual work that needed doing, and any custom code}{5}}
\pgfsyspdfmark {pgfid27}{7328055}{25246518}
\pgfsyspdfmark {pgfid30}{36188921}{25244225}
\pgfsyspdfmark {pgfid31}{38040312}{25025335}
\@writefile{toc}{\contentsline {paragraph}{Numpy/OpenCV powered metrics, utilising image based calculations}{5}}
\@writefile{toc}{\contentsline {paragraph}{Fourier/wavelet based metrics}{5}}
\newlabel{ImageQualityLivenessTestDiagram}{{A}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The architecture of the image quality liveness test. (A) The greyscale copy of the image, and a blurred copy of the image are input into each of the metrics. (B) The metrics are individually calculated, and a single value output from them. (C) These values build a 1D vector. (D) They are classified using an LDA classifier. (E) The realness value is 1.0 for real, and 0.0 for fake, or in between.}}{6}}
\citation{VideoQualityUpdated}
\citation{RRED}
\citation{SGDBetterThanAdamForImageClassification}
\@writefile{tdo}{\contentsline {todo}{Need to adjust how we specify metrics and what they are}{7}}
\pgfsyspdfmark {pgfid32}{8438196}{40031418}
\pgfsyspdfmark {pgfid35}{36188921}{40029125}
\pgfsyspdfmark {pgfid36}{38040312}{39810235}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Residual Network based 2D liveness test}{7}}
\citation{3DReconstructionMethod}
\@writefile{tdo}{\contentsline {todo}{TODO: insert citation for trying pretrained imagenet}{8}}
\pgfsyspdfmark {pgfid37}{7328055}{34133178}
\pgfsyspdfmark {pgfid40}{36188921}{34130885}
\pgfsyspdfmark {pgfid41}{38040312}{33911995}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}A system for preventing 3D spoofing attacks}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {C.1}2D to 3D Conversion}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {C.2}3D point cloud classification}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {C.3}Linking everything together}{8}}
\newlabel{2DCNNArchitecture}{{B}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The 2D CNN test architecture. We take the face image, resize to a fixed size, and put through ResNet50. The two last CNN layers of this ResNet are trainable. The output of this network is flattened and fed through a deep feed forward network, yielding one output (which is the liveness score as before).}}{9}}
\newlabel{3DClassifierArchitectureDiagram}{{C.3}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  This is an overview of the 3D classifier. \textbf  {(A)} a high resolution image is input into the classifier. \textbf  {(B)} The image goes through a HoG based face detector. The bounding box of the face is extracted, and the image is cropped. The image is then resized to be 192x192 pixels, which is what's required by the VRN process. \textbf  {(C)} The pretrained VRN face reconstruction model takes an image input, and outputs a voxel representation. Some postprocessing from the VRN model is necessary to convert an occupancy grid into a voxel representation (this is done here rather than in the VoxNet model). \textbf  {(D)} The VoxNet classifier uses several 3D convolutional layers, along with a couple of Dense layers to classify. \textbf  {(E)} The output of the last dense layer is simply a single number defined as the certainty of realness. 1.0 implies the model is certain that the input is real, while 0.0 implies the model is certain that the input is faked. }}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D}Datasets for training and testing}{10}}
\@writefile{tdo}{\contentsline {todo}{Mention more detail here, and cite more information about our implementation e.g. with H5Py for caching, the use of generators for testing/training}{10}}
\pgfsyspdfmark {pgfid42}{7328055}{17604041}
\pgfsyspdfmark {pgfid45}{36188921}{17601748}
\pgfsyspdfmark {pgfid46}{38040312}{17382858}
\@writefile{toc}{\contentsline {subsection}{\numberline {E}Visualisation and Demonstration}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Results}{10}}
\citation{VoxNetModel}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Image Quality Liveness Test}{11}}
\@writefile{tdo}{\contentsline {todo}{Add False Positive/False Negative accuracy here}{11}}
\pgfsyspdfmark {pgfid47}{7328055}{44714797}
\@writefile{tdo}{\contentsline {todo}{Add time to conduct computation here (without multithreading) - for predictions only, not training}{11}}
\pgfsyspdfmark {pgfid52}{7328055}{44714797}
\pgfsyspdfmark {pgfid50}{36188921}{44712504}
\pgfsyspdfmark {pgfid51}{38040312}{44493614}
\pgfsyspdfmark {pgfid55}{36188921}{39493560}
\pgfsyspdfmark {pgfid56}{38040312}{39274670}
\@writefile{tdo}{\contentsline {todo}{show an example image of the system at work with image quality liveness}{11}}
\pgfsyspdfmark {pgfid57}{7328055}{43928365}
\pgfsyspdfmark {pgfid60}{36188921}{30994538}
\pgfsyspdfmark {pgfid61}{38040312}{30775648}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}2D Convolutional Neural Network Liveness Test}{11}}
\@writefile{tdo}{\contentsline {todo}{Insert time here to isolate face/preprocess}{11}}
\pgfsyspdfmark {pgfid62}{7328055}{40712212}
\@writefile{tdo}{\contentsline {todo}{Insert time here to conduct neural network prediction}{11}}
\pgfsyspdfmark {pgfid67}{7328055}{40712212}
\@writefile{tdo}{\contentsline {todo}{Insert system performance (specs of Lexo)}{11}}
\pgfsyspdfmark {pgfid72}{7328055}{40712212}
\@writefile{tdo}{\contentsline {todo}{}{11}}
\pgfsyspdfmark {pgfid77}{7328055}{40712212}
\pgfsyspdfmark {pgfid65}{36188921}{24261739}
\pgfsyspdfmark {pgfid66}{38040312}{24042849}
\pgfsyspdfmark {pgfid70}{36188921}{20481309}
\pgfsyspdfmark {pgfid71}{38040312}{20262419}
\pgfsyspdfmark {pgfid75}{36188921}{15262365}
\pgfsyspdfmark {pgfid76}{38040312}{15043475}
\pgfsyspdfmark {pgfid80}{36188921}{10730231}
\pgfsyspdfmark {pgfid81}{38040312}{10511341}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}3D VoxNet Liveness Test}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Evaluation}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Improvements}{11}}
\@writefile{toc}{\contentsline {paragraph}{Representing 3D Attacks}{11}}
\@writefile{toc}{\contentsline {paragraph}{Dealing with source quality attacks that use holes in web browsers}{11}}
\@writefile{tdo}{\contentsline {todo}{Mention the GetUserMedia API that is used}{11}}
\pgfsyspdfmark {pgfid82}{7328055}{11935142}
\@writefile{tdo}{\contentsline {todo}{Source from https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia regarding the security aspects }{11}}
\pgfsyspdfmark {pgfid87}{7328055}{11935142}
\pgfsyspdfmark {pgfid85}{36188921}{9680066}
\pgfsyspdfmark {pgfid86}{38040312}{9461176}
\pgfsyspdfmark {pgfid90}{36188921}{5247554}
\pgfsyspdfmark {pgfid91}{38040312}{5028664}
\@writefile{toc}{\contentsline {paragraph}{Existing BIQI implementation}{11}}
\@writefile{tdo}{\contentsline {todo}{ADD Calculations here for speed with hard drive, SSD, and memory}{11}}
\pgfsyspdfmark {pgfid92}{13591583}{8631031}
\pgfsyspdfmark {pgfid95}{36188921}{-878527}
\pgfsyspdfmark {pgfid96}{38040312}{-1097417}
\bibstyle{plain}
\bibdata{report}
\bibcite{VideoQualityOriginal}{{1}{}{{}}{{}}}
\bibcite{DeepNeuralNetworkDeployability}{{2}{}{{}}{{}}}
\bibcite{ReplayAttackDataset}{{3}{}{{}}{{}}}
\bibcite{SFMClassifier}{{4}{}{{}}{{}}}
\bibcite{3DMadDataset}{{5}{}{{}}{{}}}
\bibcite{ImageQualityAssessmentTest}{{6}{}{{}}{{}}}
\bibcite{3DReconstructionMethod}{{7}{}{{}}{{}}}
\bibcite{AlexNet}{{8}{}{{}}{{}}}
\bibcite{FaceSpoofingAttacksStudy}{{9}{}{{}}{{}}}
\bibcite{VoxNetModel}{{10}{}{{}}{{}}}
\bibcite{VideoQualityUpdated}{{11}{}{{}}{{}}}
\bibcite{Patel2016CrossDatabaseFA}{{12}{}{{}}{{}}}
\bibcite{GoogLeNet}{{13}{}{{}}{{}}}
\bibcite{NUAADataset}{{14}{}{{}}{{}}}
\bibcite{SGDBetterThanAdamForImageClassification}{{15}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusions}{12}}
