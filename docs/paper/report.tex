\documentclass[10pt,a4paper]{article}
\usepackage{times}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{durhampaper}
\usepackage{subfigure}
\usepackage{todonotes}
% \usepackage{harvard}
% \usepackage[moderate]{savetrees}
\usepackage{url}

\title{Facial Liveness Testing: For The Web}
\author{} % leave; your name goes into \student{}
\student{Ryan Collins}
\supervisor{Prof A. Krokhin}
\degree{MEng Computer Science}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
% These instructions give you guidelines for preparing the final paper.  DO NOT change any settings, such as margins and font sizes.  Just use this as a template and modify the contents into your final paper.  Do not cite references in the abstract.

% The abstract must be a Structured Abstract with the headings {\bf Context/Background}, {\bf Aims}, {\bf Method}, {\bf Results}, and {\bf Conclusions}.  This section should not be longer than half of a page, and having no more than one or two sentences under each heading is advised.
\paragraph{Context}
    \todo{TODO}

\paragraph{Aims}
    % This might belong more in the method.
    \begin{itemize}
        \item Verify the results of the Image Quality Assessment test.
        \item Assess the outcome Convolutional Neural Networks on classifying real/spoofed images.
        \item Design and implement a new 3D based liveness test, aimed to prevent mask attacks.
        \item Determine the outcome of fusing the three above methods together, and how successful this is.
    \end{itemize}

\paragraph{Method}
   
    \todo{TODO}
\paragraph{Results}
    \todo{TODO}
\paragraph{Conclusions}
    \todo{TODO}

\end{abstract}

\begin{keywords}
Facial liveness, convolutional neural networks, image quality metrics
\end{keywords}

\section{Introduction}
    % What is the project about?
    Currently, username and password authentication is commonplace throughout the web. However, username and password
    based authentication systems have a number of problems. Some common passwords can be broken using dictionary attacks,
    especially if they consist partially or entirely of a word in a standard dictionary. Furthermore, the process of shoulder surfing is possible (watching out
    for someone's password, and how they type it).

    % TODO this needs to be readjusted to make it sound more formal and clear.
   While there are different measures of detecting liveness, each method is specialised towards defending against a given attack. The aim of this project is to understand
   the existing liveness detection methods, which type of attack they aim to prevent, and how effective they are. Once this has been achieved, the aim shall be to bring
   each of these methods together, hopefully improving the effectiveness of such a system by encorporating multiple methods.

    % TODO might be worth explaining that we are focusing here on only images, rather than video. Explain why...

    In this context, we propose a novel new 3D-based liveness test, based on a two part approach: (i) VRN based 3D reconstruction (ii) VoxNet based 3D classification.
    We also confirm the success of the Image Quality Assessment method for Facial Liveness, and provide an improve
    % In this context, we propose 

\section{Related Work}
    % LIT REVIEW GOES HERE!
    As defined in \cite{FaceSpoofingAttacksStudy}, the types of face spoofing attacks can be described under three sections: Photo Attack, Video Attack and Mask Attack.

    \subsection{2D Spoofing Attacks}
        Photo and Video Attacks are both 2D spoofing attacks, which involve using a previously retrieved photo/video, and holding it in front of a camera. In the case of photo attacks,
        a single photo is used, where in video, some video would be played back on a screen. \cite{FaceSpoofingAttacksStudy}.

        With video-based facial recognition systems, motions of some form can be used to determine whether the person is real or spoofed, such as blinking, head movement and others.
        % TODO "As shown in ..., a blinking method using ... yields ... results
        % Head movement methods shown in .... yield ... by using ...
        % Face flashing methods, recently proposed in ..., yield impressive results, but require a screen and the results vary based on screen size.
        In the method defined in \cite{SFMClassifier}, structure from motion was used on the video to produce a 3D model of a user, with the depth channel being used to determine whether a person is real, or whether it's simply an image.
        They also extended this by fusing this method with audio verification. The fusion of multiple methods provides greater reliablity. However, while SFM works with video, it doesn't work with a single image,
        and it also doesn't work if a video with little motion is provided. This fusion was completed using a Bayesian Network 

        While motion based methods are video-only, quality based methods are useful for both videos and images (either by extracting key video frames or using all video frames and combining the results).
        %TODO explain old image quality methods, and their results and how they work. What's bad/what's good?

        While there are various quality metrics that have been used, combining a large number of them can yield some increased accuracy. By combining 25 different metrics,
        , yielding the resulting metric values into a large vector, and using that as input to a classifier (an LDA), this yields fairly high accuracy. \cite{ImageQualityAssessmentTest}.
        This is an example of combining many items to yield better results. While each metric on its own isn't that great, using them all together yields better results.
        
        Recently, deep learning based approaches have been taken to facial liveness (both video and image based).
        % Some existing CNN based methods.
        % then explain Alexnet's success previously with image classification, and by extension residual networks extension.

    \subsection{3D Spoofing Attacks}
        Mask Attacks are a 3D spoofing attack, which involve creating a 3D mask of someone and wearing it. \cite{FaceSpoofingAttacksStudy} These are much less prevalent, but with 3D printing becoming more mainstream, this
        could potentially get more prevalent in the future.

        % Explain the method shown in Choudhary et al., 1999 - SFM. Problem: depth information ahrd to obtain when still with SFM. Noise also problematic.
        % Which uses Structure From Motion.

        
    % What are the different types of attacks that one would expect? 
    % Then, explain the different methods that can be applied, including references.
    % - image Quality assessment (different types of image quality metrics used ,and why they should be effective). Drawbacks of these
    % - movement based assessment (requiring actions to be performed, and their problems).
    % - Deep Learning methods (what methods exist, their performance)
    % - 3D mask prevention methods (kinect based ones that require 3D input, or SFM, which isn't really valid here)


\section{Solution}
    % Solution to the problem
    \subsection{Image Quality Assessment based liveness test}
        For 2D spoofing attacks, spoofed images are typically lower quality than the real images, and thus by measuring the image quality
        one can train a classifier to detect real and spoofed images respectively.

        The method used, based on the work of \citet{ImageQualityAssessmentTest}, implements 24 different metrics with varying differences, and produces
        a vector for each image. Initially, classification was done using a Support Vector Machine (SVM), but after experimentation this proved to be fairly
        unreliable (yielding 70\% accuracy on the test set). The classifier was later changed to use Linear Discriminant Analysis (LDA) which yielded a much improved
        accuracy (96\% accuracy on the test set). \todo[inline]{TODO: give more accuracy figures of accuracy here, I can't remember the exact numbers}.

    \subsection{Residual Network based 2D liveness test}
        Recently, 2D convolutional neural networks have had great success in image classification tasks. Therefore, it might be possible to train
        a residual neural network (resnet) to classify for facial liveness tasks.

        In order to simplify the process of training, an existing resnet model (ResNet50) was used, with only the final convolutional layer being
        set to trainable. This is because the initial convolutional layers contain the standard features contained within images, while the final one
        learns bundles of features. Internal feed forward activations use relu, while the external output uses the softmax activation function

        Training was completed using the categorical cross-entropy loss function (as this is considered multiclass).
        We yield a 2-tuple output from this model, which is the probability of each possible case. We take the value with the highest probability as the true outcome.

        The output of this ResNet model is then fed into a 2D Max Pooling layer, which then feeds into a feed forward neural network.
        Initially, the model was trained using the Adam optimiser, but this yielded poor accuracy (75\% accuracy). Utilising the standard
        gradient descent (SGD) optimiser with a low learning rate yielded far greater accuracy.

        \missingfigure{TODO: insert diagram of architecture of our final resnet model}
        \todo{TODO: insert citation for trying pretrained imagenet}

    \subsection{A system for preventing 3D spoofing attacks}
        While the systems before might go partially towards preventing 3D spoofing attacks, though primarily considering the 2D image, we now propose a method
        that is designed for classifying facial liveness based on a 3D point cloud.

        \subsubsection{2D to 3D Conversion}
            In order to classify an image/video, the 2D image needs to be converted to a 3D representation of a user's face. While 3d reconstruction is easier with videos (using structure from motion or other multiview based methods),
            there also exist image-based reconstruction methods such as vrn (\citealt{3DReconstructionMethod}) which are more specific and designed for reconstructing faces based on images. This also has benefits, as structure from motion
            is unable to reconstruct 3D from a single image, or from videos with very little motion.

            The image was converted by first applying a facial detection algorithm on the image, and cropping the image down to provide only the face. This cropped image was then resized to
            be of size $(192, 192)$, still in colour. This cropped and resized image was then fed through the VRN network. After this, the network output was filtered and stacked to provide the voxel input required.

            The code to operate this can be found under the \emph{liveness.vox.reconstruction} namespace within the code.

        \subsubsection{3D point cloud classification}
            Once the 3D reconstruction is obtained, one can then classify this using some model to produce the fake/real metric.
            
            VoxNet takes in a point cloud and converts this to an occupancy grid. This is then fed through two convolutional layers,
            pooled, and then goes through a dense layer before reaching the classifier output (a dense layer with the k outcomes). 

            As a pretrained version of VoxNet wasn't readily available, the whole system was trained together from scratch.

        \subsubsection{Linking everything together}
            While each system is self-contained, linking them together took a little bit more work than expected. The models themselves couldn't be directly joined together,
            as VRN required extra postprocessing steps which couldn't be implemented using tensors within tensorflow. As such, the initial 2D to 3D conversion was required to be run
            as a preprocessing step.

            To assist in the training phase, a generator was written in Python to conduct the postprocessing on the fly for each batch, which didn't require the entire preprocessing step to be done before training, 
            thus reducing the peak memory usage problems. While an ImageDataGenerator was used previously, this isn't compatible with 3D, and therefore a custom module needed to be written.

            Once the preprocessing had been completed, the preprocessed image was fed to the VoxNet. 

            % tODO explain experiments.
            \missingfigure{INSERT FIGURE HERE CONTAINING PIPELINE}
    \subsection{Visualisation and Demonstration}
        In order to visualise the overall outcome of facial liveness, a generic model 
\section{Results}
    % based on the solution, what results did we yield? What did we find out?
    \textbf{TODO results}
\section{Evaluation}
    % How well our system works, how well did it assess stuff, and how it can be improved.
    % what are the uses of our research? e.g. influence and improve the design of xyz...
    \textbf{TODO evaluation}


    % Improvements:
    % 3D attacks more difficult. One could extend this method using 3D reconstruction (sfm based on videos)
    % then recovering 3D details, and using these as input features.
    % this would allow for 3D reconstruction to some extent. Would require video input.
\section{Conclusions}
    % overall, what did the project show?


\bibliographystyle{plain}
\bibliography{report}

\end{document}