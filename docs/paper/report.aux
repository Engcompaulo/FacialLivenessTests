\relax 
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{report.ist}
\@glsorder{word}
\@writefile{toc}{\contentsline {paragraph}{Context}{1}}
\@writefile{toc}{\contentsline {paragraph}{Aims}{1}}
\@writefile{toc}{\contentsline {paragraph}{Method}{1}}
\@writefile{toc}{\contentsline {paragraph}{Results}{1}}
\@writefile{toc}{\contentsline {paragraph}{Conclusions}{1}}
\citation{NPRArticle}
\citation{FaceSpoofingAttacksStudy}
\citation{FaceSpoofingAttacksStudy}
\citation{SFMClassifier}
\citation{SFMClassifier}
\citation{BlinkDetectionLivenessTest}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}2D Spoofing Attacks}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1}Video-based tests}{2}}
\@writefile{toc}{\contentsline {paragraph}{Depth-based liveness}{2}}
\citation{ImageQualityAssessmentTest}
\citation{Patel2016CrossDatabaseFA}
\@writefile{toc}{\contentsline {paragraph}{Blink Detection}{3}}
\@writefile{toc}{\contentsline {paragraph}{Face Flashing}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2}Quality-based tests}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.3}Neural Networks, and their structure}{3}}
\@writefile{toc}{\contentsline {paragraph}{Fully connected layers}{3}}
\@writefile{toc}{\contentsline {paragraph}{Convolutional layers}{3}}
\@writefile{toc}{\contentsline {paragraph}{A note about parameters}{3}}
\@writefile{toc}{\contentsline {paragraph}{Cross-Database Approach}{3}}
\citation{AlexNet}
\citation{DeepNeuralNetworkDeployability}
\citation{DeepNeuralNetworkDeployability}
\citation{GoogLeNet}
\citation{DeepResidualNetworks}
\citation{DeepResidualNetworks}
\citation{DeepNeuralNetworkDeployability}
\citation{DeepNeuralNetworkDeployability}
\citation{DeepNeuralNetworkDeployability}
\citation{DeepNeuralNetworkDeployability}
\citation{DeepNeuralNetworkDeployability}
\citation{DeepNeuralNetworkDeployability}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.4}General 2D image classification models}{4}}
\@writefile{toc}{\contentsline {paragraph}{AlexNet}{4}}
\@writefile{toc}{\contentsline {paragraph}{VGG16 Network}{4}}
\@writefile{toc}{\contentsline {paragraph}{GoogLeNet Inception}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A Residual Block: this is the building block of the ResNet architecture. Source: \cite  {DeepResidualNetworks}\relax }}{4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{ResidualBlock}{{1}{4}}
\@writefile{toc}{\contentsline {paragraph}{Residual Networks}{4}}
\citation{NUAADataset}
\citation{ReplayAttackDataset}
\citation{FaceSpoofingAttacksStudy}
\citation{3DMadDataset}
\citation{SFMClassifier}
\newlabel{Top1AccuracyOverNetwork}{{2a}{5}}
\newlabel{sub@Top1AccuracyOverNetwork}{{a}{5}}
\newlabel{Top1AccuracyOverOperations}{{2b}{5}}
\newlabel{sub@Top1AccuracyOverOperations}{{b}{5}}
\newlabel{ComparisonsOfDifferentModels}{{\caption@xref {ComparisonsOfDifferentModels}{ on input line 260}}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces These two charts, from \cite  {DeepNeuralNetworkDeployability}, show the accuracy and computational requirements of each type of classifier.\relax }}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.5}Datasets}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}3D Spoofing Attacks}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Dataset}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {C.1}Obtaining 3D data from 2D images/video}{5}}
\@writefile{toc}{\contentsline {paragraph}{Structure from Motion (SFM)}{5}}
\citation{VoxNetModel}
\citation{VoxNetModel}
\citation{3DReconstructionMethod}
\citation{PointNet}
\citation{VoxNetModel}
\@writefile{toc}{\contentsline {paragraph}{Single Image 3D Face Reconstruction (VRN)}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The original VoxNet architecture. While point cloud input is available, voxel based representation can also be used. Diagram obtained from \cite  {VoxNetModel}\relax }}{6}}
\newlabel{OriginalVoxNetArchitecture}{{3}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {C.2}3D Classifiers}{6}}
\@writefile{toc}{\contentsline {paragraph}{PointNet}{6}}
\@writefile{toc}{\contentsline {paragraph}{VoxNet}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Solution}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Specification, and design requirements}{6}}
\newlabel{SpecPoint1}{{1}{6}}
\newlabel{SpecPoint2}{{2}{6}}
\newlabel{SpecPoint3}{{3}{6}}
\newlabel{SpecPoint4}{{4}{6}}
\newlabel{SpecPoint5}{{5}{6}}
\newlabel{SpecPoint6}{{6}{6}}
\newlabel{SpecPoint7}{{7}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Shared Services}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {B.1}Dataset Managers}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {B.2}Neural Network Infrastructure}{7}}
\@writefile{toc}{\contentsline {paragraph}{Neural Network Framework}{7}}
\@writefile{toc}{\contentsline {paragraph}{Hardware for training}{7}}
\citation{ImageQualityAssessmentTest}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The architecture of the image quality liveness test. (A) The greyscale copy of the image, and a blurred copy of the image are input into each of the metrics. (B) The metrics are individually calculated, and a single value output from them. (C) These values build a 1D vector. (D) They are classified using an LDA classifier. (E) The realness value is 1.0 for real, and 0.0 for fake, or in between.\relax }}{8}}
\newlabel{ImageQualityLivenessTestDiagram}{{4}{8}}
\@writefile{toc}{\contentsline {paragraph}{Hardware for testing}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {B.3}Image Processing and Computation Management}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Image Quality Assessment Liveness Test}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {C.1}Overview}{8}}
\citation{VideoQualityOriginal}
\citation{VideoQualityUpdated}
\citation{BIQIImplementation}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {C.2}The Metrics}{9}}
\@writefile{toc}{\contentsline {paragraph}{PyVideoQuality Library}{9}}
\@writefile{toc}{\contentsline {paragraph}{Blind Image Quality Index (BIQI)}{9}}
\@writefile{toc}{\contentsline {paragraph}{Gradient Magnitude Error (GME)}{9}}
\@writefile{toc}{\contentsline {paragraph}{Gradient Phase Error (GPE)}{9}}
\@writefile{toc}{\contentsline {paragraph}{High Low Frequency Index (HLFI)}{9}}
\citation{JQIPaper}
\citation{LMSEPaper}
\citation{LMSEPaper}
\citation{LMSEPaper}
\citation{LMSEPaper}
\@writefile{toc}{\contentsline {paragraph}{JPEG Quality Index (JQI)}{10}}
\@writefile{toc}{\contentsline {paragraph}{Laplacian Mean Squared Metric (LMSE)}{10}}
\@writefile{toc}{\contentsline {paragraph}{Mean Angle Magnitude Similarity (MAMS)}{10}}
\@writefile{toc}{\contentsline {paragraph}{Mean Angle Similarity (MAS)}{10}}
\@writefile{toc}{\contentsline {paragraph}{R-Averaged Metric (RAMD)}{10}}
\@writefile{toc}{\contentsline {paragraph}{Spectral Magnitude Error (SME)}{10}}
\@writefile{toc}{\contentsline {paragraph}{Spectral Phase Error (SPE)}{10}}
\citation{ImageQualityAssessmentTest}
\citation{ImageQualityAssessmentTest}
\citation{ImageQualityAssessmentTest}
\citation{ImageQualityAssessmentTest}
\@writefile{toc}{\contentsline {paragraph}{Total Corner Difference (TCD)}{11}}
\@writefile{toc}{\contentsline {paragraph}{Total Edge Difference (TED)}{11}}
\@writefile{toc}{\contentsline {paragraph}{Visual Information Fidelity (VIFD)}{11}}
\@writefile{toc}{\contentsline {paragraph}{The other metrics used}{11}}
\@writefile{toc}{\contentsline {paragraph}{The RRED Problem}{11}}
\@writefile{toc}{\contentsline {paragraph}{Testing these metrics}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {C.3}Classifier}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D}2D based CNN Liveness Test}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.1}Overview}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.2}Data Preprocessing}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces This is the output produced from the preprocessing step of the ResNet based method.\relax }}{12}}
\newlabel{FaceExtraction}{{5}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.3}The Model}{12}}
\@writefile{toc}{\contentsline {paragraph}{Early attempts with AlexNet}{12}}
\@writefile{toc}{\contentsline {paragraph}{Residual Networks}{12}}
\@writefile{toc}{\contentsline {paragraph}{Feed Forward Classifier}{12}}
\citation{liu_liu_2017}
\citation{liu_liu_2017}
\citation{SGDBetterThanAdamForImageClassification}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The 2D CNN test architecture. We take the face image, resize to a fixed size, and put through ResNet50. The two last CNN layers of this ResNet are trainable. The output of this network is flattened and fed through a deep feed forward network, yielding one output (which is the liveness score as before).\relax }}{13}}
\newlabel{2DCNNArchitecture}{{6}{13}}
\@writefile{toc}{\contentsline {paragraph}{The Problem with Activation Functions}{13}}
\@writefile{toc}{\contentsline {paragraph}{The Problem with a Single Neuron Output}{13}}
\@writefile{toc}{\contentsline {paragraph}{Normalization and Dropout}{13}}
\citation{3DReconstructionMethod}
\citation{VRNTorchToKeras}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.4}The Training Process}{14}}
\@writefile{toc}{\contentsline {paragraph}{Optimizer}{14}}
\@writefile{toc}{\contentsline {paragraph}{Loss Function}{14}}
\@writefile{toc}{\contentsline {paragraph}{Data Generators}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E}3D Face Reconstruction Liveness Test}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {E.1}Overview}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {E.2}Preprocessing Part 1: Extracting Facial Data}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {E.3}3D Facial Reconstruction}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  This is an overview of the 3D classifier. \textbf  {(A)} a high resolution image is input into the classifier \textbf  {(B)} Preprocessing (facial extraction, and resize to 192x192) \textbf  {(C)} 2D to 3D reconstruction \textbf  {(D)} Conv3D layers along with feed-forward layers, used for learning the classification \textbf  {(E)} A single realness metric is output, 1.0 implies real, while 0.0 implies spoofing has occurred. \relax }}{14}}
\newlabel{3DClassifierArchitectureDiagram}{{7}{14}}
\citation{KerasVoxNetBug}
\citation{3DMadDataset}
\citation{ImageQualityAssessmentTest}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {E.4}3D Classification}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {E.5}The Training Process}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {E.6}The Dataset}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {F}Consolidation Layer}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Results}{15}}
\newlabel{ResultsTable}{{1a}{16}}
\newlabel{sub@ResultsTable}{{a}{16}}
\newlabel{WallClockResultsTime}{{1b}{16}}
\newlabel{sub@WallClockResultsTime}{{b}{16}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Tables showing all numerical results recorded for the two liveness tests.\relax }}{16}}
\newlabel{TableOfResultsAll}{{1}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Outputs from the \emph  {live\_webcam\_output.py} file, being run on two different videos from the Replay-Attack test dataset. The model predicted the correct output here.\relax }}{16}}
\newlabel{SystemWorkingScreenshots}{{8}{16}}
\newlabel{RealScreenshot}{{8a}{16}}
\newlabel{sub@RealScreenshot}{{a}{16}}
\newlabel{FakeScreenshot}{{8b}{16}}
\newlabel{sub@FakeScreenshot}{{b}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Testing Process}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1}Datasets}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2}Accuracy}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.3}Confusion Matrix}{16}}
\@writefile{toc}{\contentsline {paragraph}{True Positives}{16}}
\@writefile{toc}{\contentsline {paragraph}{False Positives}{16}}
\citation{ImageQualityAssessmentTest}
\citation{VoxNetModel}
\@writefile{toc}{\contentsline {paragraph}{True Negatives}{17}}
\@writefile{toc}{\contentsline {paragraph}{False Negatives}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Image Quality Liveness Test}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}2D Convolutional Neural Network Liveness Test}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D}3D VoxNet Liveness Test}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E}Consolidation Layer}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces A plot of ResNet output against WIQA output. While a perceptron could be used (due to the linearly separable nature), this would effectively yield a logical AND or OR gate with 2 liveness tests.\relax }}{18}}
\newlabel{LinearlySeparableGraph}{{9}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {F}Live Application}{18}}
\@writefile{toc}{\contentsline {paragraph}{Benefits of CNN facial isolation}{18}}
\@writefile{toc}{\contentsline {paragraph}{Resolution problems with WIQA test}{18}}
\@writefile{toc}{\contentsline {paragraph}{Uncertainty of the CNN liveness test}{18}}
\@writefile{toc}{\contentsline {paragraph}{Problem in running liveness tests in series}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Evaluation}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Usefulness of our system}{19}}
\@writefile{toc}{\contentsline {paragraph}{Quality Test}{19}}
\@writefile{toc}{\contentsline {paragraph}{2D CNN}{19}}
\@writefile{toc}{\contentsline {paragraph}{3D VoxNet Liveness Test}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Improvements}{19}}
\@writefile{toc}{\contentsline {paragraph}{Representing 3D Attacks}{19}}
\@writefile{toc}{\contentsline {paragraph}{More Liveness Tests}{19}}
\@writefile{toc}{\contentsline {paragraph}{Existing BIQI implementation}{19}}
\@writefile{toc}{\contentsline {paragraph}{Replacing ResNet50 with a larger ResNet model}{19}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusions}{19}}
\bibstyle{abbrv}
\bibdata{report}
\bibcite{DeepNeuralNetworkDeployability}{{1}{}{{}}{{}}}
\bibcite{ReplayAttackDataset}{{2}{}{{}}{{}}}
\bibcite{SFMClassifier}{{3}{}{{}}{{}}}
\bibcite{VideoQualityUpdated}{{4}{}{{}}{{}}}
\bibcite{BIQIImplementation}{{5}{}{{}}{{}}}
\bibcite{3DMadDataset}{{6}{}{{}}{{}}}
\bibcite{ImageQualityAssessmentTest}{{7}{}{{}}{{}}}
\bibcite{LMSEPaper}{{8}{}{{}}{{}}}
\bibcite{DeepResidualNetworks}{{9}{}{{}}{{}}}
\bibcite{VideoQualityOriginal}{{10}{}{{}}{{}}}
\bibcite{3DReconstructionMethod}{{11}{}{{}}{{}}}
\bibcite{KerasVoxNetBug}{{12}{}{{}}{{}}}
\bibcite{NPRArticle}{{13}{}{{}}{{}}}
\bibcite{AlexNet}{{14}{}{{}}{{}}}
\bibcite{FaceSpoofingAttacksStudy}{{15}{}{{}}{{}}}
\bibcite{liu_liu_2017}{{16}{}{{}}{{}}}
\bibcite{VRNTorchToKeras}{{17}{}{{}}{{}}}
\bibcite{VoxNetModel}{{18}{}{{}}{{}}}
\bibcite{BlinkDetectionLivenessTest}{{19}{}{{}}{{}}}
\bibcite{Patel2016CrossDatabaseFA}{{20}{}{{}}{{}}}
\bibcite{PointNet}{{21}{}{{}}{{}}}
\bibcite{GoogLeNet}{{22}{}{{}}{{}}}
\bibcite{NUAADataset}{{23}{}{{}}{{}}}
\bibcite{JQIPaper}{{24}{}{{}}{{}}}
\bibcite{SGDBetterThanAdamForImageClassification}{{25}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
