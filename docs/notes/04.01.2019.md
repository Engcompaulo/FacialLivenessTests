# 4th February 2019
Towards building a neural network classifier.

## Accuracy vs Top_K_Categorical_Accuracy
Today I realised that the accuracy measure is really poor for judging the result of a neural network for liveness.
When we one hot encode the output (yielding a 2-tuple output, with a certainty), the accuracy could yield around 0.7, while
the categorical accuracy could be 1.0

Our goal here is to ensure that in a tuple (a, b), that a>b or b>a depending on the condition, and while in an ideal world we might
want a/b to be zero, in practice it just is required to hold that condition above.

Therefore, yielding a 75% accuracy might actual result in a very high top_2_categorical accuracy, by following this contraint.
In the case of the fake/real validation set, when we run evaluate, the accuracy itself is around 37%, but the top_k_categorical
is actually very high.

# Dropout
Droput is high on the final dense classifier (0.6 but only on one layer) which seemed to slowly help improve results.

## Forward towards VoxNet:

Learning this, we can now improve the overall outcome of VoxNet when we code it.
